---
title: "Replication of Social Intuition: Behavioral and Neurological Considerations by Jellema et al. (2024, Frontiers in Psychology)"
author: "Wilder Hartwell (wphartwell@ucsd.edu"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

**Link to experiment:** <https://psyc-201.github.io/jellema2024/jellema2024_9.html>

This paper was one of the inspirations for my first year project. It includes a social implicit learning paradigm, which is what I am doing in my first year project. As the title of the paper suggests, it looks at social intuition, which is my central research interest. The study is also done in neurotypical participants but administers the autism quotient to look at correlations between autistic traits and other variables of interest. This makes the study more practical for an in class replication on a short timeline. Another benefit of this study is that it doesn’t use any skills that are too far out of my reach, but still presents some opportunities for growth.

In the acquisition phase, face morphs of dynamic facial expressions (happy or angry) in which their gaze shifts towards or away from the participant will be shown to participants across multiple trials. All faces are either identity A or B. Identity A and B are showing either a positive or negative disposition towards the participant. In the test phase, implicit learning was tested via morphs of the facial expressions of both identities put together, progressively shifting towards more of one identity than the other, while participants indicated whether the identity was closer to A or B. The smiling and the frowning faces were tested separately. The idea was that if the participant had learned the disposition of the two identities, they would be able to indicate whether the face was more A or B.

I will give 56 trials split into two blocks of 28 trials in the acquisition phase. The response in the test phase will ask participants to press "f" or "j" to indicate that they think the face is more identity A or B after viewing the video clip on each trial. In the nonsocial task, participants will do the same thing except identities A and B are actually circle vs. square.

The test phase will be four blocks of ten trials. It starts with 60% maximally smiling agent A and 40% maximally smiling agent B and progresses in steps of 5% towards 60% maximally smiling agent B, which only takes 5 trials. I'd like to give participants two rounds of the smiling trials. Then the same thing is repeated for the frowning faces, and I would give two rounds of that as well. Their accuracy scores in the test phase will serve as the measure of their implicit learning. At the end, participants will be asked questions probing whether they detected the contingencies in the experiment and if they did their data will be excluded.

In the original experiment, there is also a nonsocial task, but that will not be replicated due to feasibility on a very short timeline.

I attempted to get the face stimuli from the authors but was not successful.

## Methods

35 adult participants were recruited for this study. The study was run on Prolific and participants were compensated for their time. The experiment took approximately 10-15 minutes to complete. For the face stimuli, photos were taken and then manipulated to create Identity B. The experiment was coded in jsPsych.

There were two blocks of 28 trials in the acquisition phase. In the acquisition phase, the happy face condition started with gaze forward, smiling and gradually shifted to gaze away from the participant, frowning. The angry condition started with gaze forward, frowning and gradually shifted to gaze away from the participant, smiling. The clips were 2s long.

There were four blocks of 10 trials in the test phase. The test phase began with a combined face of 60% maximally smiling agent A and 40% maximally smiling agent B and progressed in steps of 5% towards 60% maximally smiling agent B. Participants saw this four times. Then the same thing was repeated for the frowning faces, and the participants saw this four times as well. At the end, participants were asked questions probing whether they detected the contingencies in the experiment and if they did their data was excluded.

### Power Analysis

A power analysis run using an ANOVA in RStudio using the smallest original main effect of ηp\^2 = 0.12 (disposition) found that I would need 30 participants to achieve a power of 80%. Thus, I planned to recruit 35 participants to account for not all data being usable. This is a feasible number of participants to recruit with the resources available.

### Analysis Plan

---
title: "StatsReplicationOfJellema2024"
format: html
editor: visual
---

```{r setup}
knitr::purl("/Users/wilderhartwell/Documents/jellema2024/StatReplicationJellema2024.qmd",
            output = "extracted_code.R")

```

**Install packages**

```{r install packages}
library(tidyverse)
library(ggplot2) # plotting
library(ggthemes) # good for making plots pretty
library(effectsize)
library(knitr)
library(kableExtra)
```

**Prepare the non-ANOVA data set**

```{r data prep 1}
#import csv
data <- read.csv(file = "/Users/wilderhartwell/Documents/PSYCH201/PilotA_Replication.csv", header = FALSE)
                 
#make tibble
data <- tibble(data)

#convert columns to rows
data_long <- as.data.frame(t(data))

# Rename columns
colnames(data_long) <- as.character(unlist(data_long[1, ]))  # make first row the column names
data_long <- data_long[-1, ]                                 # remove the first row


# Recode words into numeric values
data_long <- data_long |>
  mutate(Q1_num = case_when(
    Q1 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q1 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    TRUE ~ NA_real_ # fallback for anything else 
    )) |>
    mutate(Q2_num = case_when(
    Q2 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q2 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q3_num = case_when(
    Q3 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q3 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q4_num = case_when(
    Q4 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q4 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q5_num = case_when(
    Q5 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q5 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q5_num = case_when(
    Q5 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q5 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q5_num = case_when(
    Q5 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q5 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q6_num = case_when(
    Q6 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q6 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q7_num = case_when(
    Q7 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q7 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q8_num = case_when(
    Q8 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q8 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q9_num = case_when(
    Q9 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q9 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q10_num = case_when(
    Q10 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q10 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(CheckQ1_num = case_when(
    CheckQ1 %in% c("I do not know") ~ 0,
    CheckQ1 %in% c("Negative") ~ 1,
    CheckQ1 %in% c("Neutral") ~ 2,
    CheckQ1 %in% c("Positive") ~ 3
    )) |>
    mutate(CheckQ2_num = case_when(
    CheckQ2 %in% c("I do not know") ~ 0,
    CheckQ2 %in% c("Negative") ~ 1,
    CheckQ2 %in% c("Neutral") ~ 2,
    CheckQ2 %in% c("Positive") ~ 3
    )) |>
    mutate(frown40_1_num = case_when(
    frown40_1 %in% c("f") ~ 0,
    frown40_1 %in% c("j") ~ 1,
    )) |>
    mutate(frown45_1_num = case_when(
    frown45_1 %in% c("f") ~ 0,
    frown45_1 %in% c("j") ~ 1,
    )) |>
    mutate(frown50_1_num = case_when(
    frown50_1 %in% c("f") ~ 0,
    frown50_1 %in% c("j") ~ 1,
    )) |>
    mutate(frown55_1_num = case_when(
    frown55_1 %in% c("f") ~ 0,
    frown55_1 %in% c("j") ~ 1,
    )) |>
    mutate(frown60_1_num = case_when(
    frown60_1 %in% c("f") ~ 0,
    frown60_1 %in% c("j") ~ 1,
    )) |>
    mutate(smile50_1_num = case_when(
    smile50_1 %in% c("f") ~ 0,
    smile50_1 %in% c("j") ~ 1,
    )) |>
    mutate(smile50_2_num = case_when(
    smile50_2 %in% c("f") ~ 0,
    smile50_2 %in% c("j") ~ 1,
    )) |>
    mutate(frown50_2_num = case_when(
    frown50_2 %in% c("f") ~ 0,
    frown50_2 %in% c("j") ~ 1,
    )) |>
    mutate(gender_num = case_when(
    Q_gender %in% c("Woman") ~ 0,
    Q_gender %in% c("Man") ~ 1,
    Q_gender %in% c("Nonbinary/other") ~ 2,
    )) |>
    mutate(age_num = case_when(
    Q_age %in% c("18-24") ~ 0,
    Q_age %in% c("25-34") ~ 1,
    Q_age %in% c("35-44") ~ 2,
    Q_age %in% c("45-54") ~ 3,
    Q_age %in% c("55-64") ~ 4,
    Q_age %in% c("65+") ~ 5,
    ))

#make characters into numeric
data_long$frown50_1_cor <- as.numeric(as.character(data_long$frown50_1_cor))
data_long$frown50_2_cor <- as.numeric(as.character(data_long$frown50_2_cor))
data_long$smile50_1_cor <- as.numeric(as.character(data_long$smile50_1_cor))
data_long$smile50_2_cor <- as.numeric(as.character(data_long$smile50_2_cor))

#the difference between the frown and smile at 50/50 (used in correlation)
FrownScore <- frown50_1_cor + frown50_2_cor
FrownScore
SmileScore <- smile50_1_cor + smile50_2_cor
SmileScore

TestScore <- FrownScore - SmileScore
data_long <- bind_cols(data_long, TestScore)

#make tibble again
data_long <- tibble(data_long)

attach(data_long)
#Score the AQ-10
AQScore <- rowSums(data_long[, c("Q1_num","Q2_num", "Q3_num", "Q4_num", "Q5_num", "Q6_num", "Q7_num", "Q8_num", "Q9_num", "Q10_num")])
as.data.frame(AQScore)
data_long <- bind_cols(data_long, AQScore)

```

**Excluding participants from data_long**

```{r exclude participants 1}
library(dplyr)

# Total participants before exclusion
n_total <- n_distinct(data_long$ID)

# Identify participants who detected contingencies (to be excluded)
excluded_detection <- data_long %>%
  filter(CheckQ1 == "Positive" & CheckQ2 == "Negative") %>%
  pull(ID)

# Identify participants with missing responses on all 50/50 trials (to be excluded)
excluded_missing <- data_long %>%
  filter(is.na(frown50_1_num) & 
         is.na(smile50_1_num) & 
         is.na(frown50_2_num) & 
         is.na(smile50_2_num)) %>%
  pull(ID)

# Combine both exclusion lists
excluded_participants <- unique(c(excluded_detection, excluded_missing))

# Label reasons for exclusion
excluded_df <- tibble(
  ID = excluded_participants,
  Reason = case_when(
    ID %in% excluded_detection ~ "Detected Contingencies",
    ID %in% excluded_missing ~ "Incomplete Responses",
    TRUE ~ "Unknown"
  )
)

# Save excluded participants to a single CSV
write.csv(excluded_df, file = "excluded_participants.csv", row.names = FALSE)

# Create dataset excluding those participants
data_complete <- data_long %>%
  filter(!(ID %in% excluded_participants))

# Print summary
cat("Excluded participants:\n")
print(excluded_df)

cat("Number excluded:", length(excluded_participants), "\n")
cat("Number remaining:", n_distinct(data_complete$ID), "\n")
```

**Demographics**

```{r demographics}
# Age distribution
ggplot(data_complete, aes(x = age_num)) +
  geom_histogram(binwidth = 1, fill = "#1976D2", alpha = 0.7) +
  labs(title = "Age Distribution",
       x = "Age",
       y = "Count") +
  scale_x_continuous(breaks = seq(min(participants$age), max(participants$age), by = 2))

# Age summary
data_complete %>%
  summarise(
    mean_age = mean(age_num, na.rm = TRUE),
    sd_age = sd(age_num, na.rm = TRUE),
    min_age = min(age_num, na.rm = TRUE),
    max_age = max(age_num, na.rm = TRUE)
  ) %>%
  kable(digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Gender distribution
ggplot(data_complete, aes(x = gender_num)) +
  geom_histogram(binwidth = 1, fill = "#1976D2", alpha = 0.7) +
  labs(title = "Gender Distribution",
       x = "Gender",
       y = "Count") +
  scale_x_continuous(breaks = seq(min(participants$age), max(participants$age), by = 2))

```

**Mean score**

```{r mean score}
acc_mean <- mean(TestScore)
acc_mean
```

**Plotting data**

```{r accuracy plot}
library(ggplot2)

ggplot(data_complete, aes(x = TestScore)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "black", alpha = 0.7) +
  labs(
    title = "Distribution of Test Scores",
    x = "Test Score",
    y = "Count"
  ) +
  theme_minimal(base_size = 14)
```

**Open spreadsheet formatted for the ANOVA**

This spreadsheet is constructed outside of R without the excluded participants

```{r ANOVA Spreadsheet}
A_data <- read.csv(file = "/Users/wilderhartwell/Documents/PSYCH201/ANOVASpreadsheet.csv")
```

**Run ANOVA**

```{r ANOVA}
#run two-way repeated measures ANOVA using aov
#looking to generate a score for each disposition? But we also have the 5 levels
#A_data_ANOVA <- A_data |>
attach(A_data)
model.aov <- aov(Response ~ 
                           Disposition * Proportion + 
                           Error(SubID/(Disposition*Proportion)))
summary(model.aov)

effectsize(model.aov)
```

**Run correlation**

```{r}
attach(data_complete)

cor.test(AQScore, TestScore)
```

## Results

### Data preparation

To prepare the data, I used RStudio. Full data preparation code is shown below.

**Install/load packages**

```{r install/loading packages}
library(tidyverse)
library(ggplot2) # plotting
library(ggthemes) # good for making plots pretty
library(effectsize)
library(knitr)
library(kableExtra)
```

**Prepare the non-ANOVA spreadsheet**

```{r data prep 2}
#import csv
data <- read.csv(file = "/Users/wilderhartwell/Documents/PSYCH201/PilotA_Replication.csv", header = FALSE)
                 
#make tibble
data <- tibble(data)

#convert columns to rows
data_long <- as.data.frame(t(data))

# Rename columns
colnames(data_long) <- as.character(unlist(data_long[1, ]))  # make first row the column names
data_long <- data_long[-1, ]                                 # remove the first row


# Recode words into numeric values
data_long <- data_long |>
  mutate(Q1_num = case_when(
    Q1 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q1 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    TRUE ~ NA_real_ # fallback for anything else 
    )) |>
    mutate(Q2_num = case_when(
    Q2 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q2 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q3_num = case_when(
    Q3 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q3 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q4_num = case_when(
    Q4 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q4 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q5_num = case_when(
    Q5 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q5 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q5_num = case_when(
    Q5 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q5 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q5_num = case_when(
    Q5 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q5 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q6_num = case_when(
    Q6 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q6 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q7_num = case_when(
    Q7 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q7 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q8_num = case_when(
    Q8 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q8 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q9_num = case_when(
    Q9 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q9 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(Q10_num = case_when(
    Q10 %in% c("Slightly Agree", "Definitely Agree") ~ 1,
    Q10 %in% c("Slightly Disagree", "Definitely Disagree") ~ 0,
    )) |>
    mutate(CheckQ1_num = case_when(
    CheckQ1 %in% c("I do not know") ~ 0,
    CheckQ1 %in% c("Negative") ~ 1,
    CheckQ1 %in% c("Neutral") ~ 2,
    CheckQ1 %in% c("Positive") ~ 3
    )) |>
    mutate(CheckQ2_num = case_when(
    CheckQ2 %in% c("I do not know") ~ 0,
    CheckQ2 %in% c("Negative") ~ 1,
    CheckQ2 %in% c("Neutral") ~ 2,
    CheckQ2 %in% c("Positive") ~ 3
    )) |>
    mutate(frown40_1_num = case_when(
    frown40_1 %in% c("f") ~ 0,
    frown40_1 %in% c("j") ~ 1,
    )) |>
    mutate(frown45_1_num = case_when(
    frown45_1 %in% c("f") ~ 0,
    frown45_1 %in% c("j") ~ 1,
    )) |>
    mutate(frown50_1_num = case_when(
    frown50_1 %in% c("f") ~ 0,
    frown50_1 %in% c("j") ~ 1,
    )) |>
    mutate(frown55_1_num = case_when(
    frown55_1 %in% c("f") ~ 0,
    frown55_1 %in% c("j") ~ 1,
    )) |>
    mutate(frown60_1_num = case_when(
    frown60_1 %in% c("f") ~ 0,
    frown60_1 %in% c("j") ~ 1,
    )) |>
    mutate(smile50_1_num = case_when(
    smile50_1 %in% c("f") ~ 0,
    smile50_1 %in% c("j") ~ 1,
    )) |>
    mutate(smile50_2_num = case_when(
    smile50_2 %in% c("f") ~ 0,
    smile50_2 %in% c("j") ~ 1,
    )) |>
    mutate(frown50_2_num = case_when(
    frown50_2 %in% c("f") ~ 0,
    frown50_2 %in% c("j") ~ 1,
    )) |>
    mutate(gender_num = case_when(
    Q_gender %in% c("Woman") ~ 0,
    Q_gender %in% c("Man") ~ 1,
    Q_gender %in% c("Nonbinary/other") ~ 2,
    )) |>
    mutate(age_num = case_when(
    Q_age %in% c("18-24") ~ 0,
    Q_age %in% c("25-34") ~ 1,
    Q_age %in% c("35-44") ~ 2,
    Q_age %in% c("45-54") ~ 3,
    Q_age %in% c("55-64") ~ 4,
    Q_age %in% c("65+") ~ 5,
    ))

#make characters into numeric
data_long$frown50_1_cor <- as.numeric(as.character(data_long$frown50_1_cor))
data_long$frown50_2_cor <- as.numeric(as.character(data_long$frown50_2_cor))
data_long$smile50_1_cor <- as.numeric(as.character(data_long$smile50_1_cor))
data_long$smile50_2_cor <- as.numeric(as.character(data_long$smile50_2_cor))

#the difference between the frown and smile at 50/50 (used in correlation)
FrownScore <- frown50_1_cor + frown50_2_cor
FrownScore
SmileScore <- smile50_1_cor + smile50_2_cor
SmileScore

TestScore <- FrownScore - SmileScore
data_long <- bind_cols(data_long, TestScore)

#make tibble again
data_long <- tibble(data_long)

attach(data_long)
#Score the AQ-10
AQScore <- rowSums(data_long[, c("Q1_num","Q2_num", "Q3_num", "Q4_num", "Q5_num", "Q6_num", "Q7_num", "Q8_num", "Q9_num", "Q10_num")])
as.data.frame(AQScore)
data_long <- bind_cols(data_long, AQScore)
```

**Exclude participants from data_long**

```{r exclude participants 2}
library(dplyr)

# Total participants before exclusion
n_total <- n_distinct(data_long$ID)

# Identify participants who detected contingencies (to be excluded)
excluded_detection <- data_long %>%
  filter(CheckQ1 == "Positive" & CheckQ2 == "Negative") %>%
  pull(ID)

# Identify participants with missing responses on all 50/50 trials (to be excluded)
excluded_missing <- data_long %>%
  filter(is.na(frown50_1_num) & 
         is.na(smile50_1_num) & 
         is.na(frown50_2_num) & 
         is.na(smile50_2_num)) %>%
  pull(ID)

# Combine both exclusion lists
excluded_participants <- unique(c(excluded_detection, excluded_missing))

# Label reasons for exclusion
excluded_df <- tibble(
  ID = excluded_participants,
  Reason = case_when(
    ID %in% excluded_detection ~ "Detected Contingencies",
    ID %in% excluded_missing ~ "Incomplete Responses",
    TRUE ~ "Unknown"
  )
)

# Save excluded participants to a single CSV
write.csv(excluded_df, file = "excluded_participants.csv", row.names = FALSE)

# Create dataset excluding those participants
data_complete <- data_long %>%
  filter(!(ID %in% excluded_participants))

# Print summary
cat("Excluded participants:\n")
print(excluded_df)

cat("Number excluded:", length(excluded_participants), "\n")
cat("Number remaining:", n_distinct(data_complete$ID), "\n")
```

### Confirmatory analysis

A two-way repeated measures ANOVA with DISPOSITION (2 levels) and PROPORTION (5 levels) as factors was performed on participant responses to the social task. This test was used because I needed to compare the means of multiple groups to see if there was a significant difference between them. A correlation was tested between the questionnaire on autistic traits and responses to the social task. This correlation test was completed because I was looking at the potential connection between autistic traits and performance on the task.
